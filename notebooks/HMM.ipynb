{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HMM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdHd9K9XsT5k"
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM, Flatten, Reshape, MaxPool1D, AveragePooling1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, TensorBoard \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime \n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY3O7FKRs07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "cad1b24e-83cd-4953-fb7a-3bbf57087b71"
      },
      "source": [
        "train_data = pd.read_csv(\"train_pos.txt\", header = None, sep=\" \", names = ['word', 'pos'], dtype = str)\n",
        "test_data = pd.read_csv(\"test_pos.txt\", header = None, sep=\" \", names = ['word', 'pos'],dtype=str)\n",
        "test_data.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rockwell</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>International</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Corp.</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'s</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tulsa</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            word  pos\n",
              "0       Rockwell  NNP\n",
              "1  International  NNP\n",
              "2          Corp.  NNP\n",
              "3             's  POS\n",
              "4          Tulsa  NNP"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggfQ7hVEw2nm",
        "outputId": "251b1e4b-73c8-48b2-e385-7f0fe1a3c1e1"
      },
      "source": [
        "s = set(\"\".join(str(train_data['word'])))\n",
        "s.remove(\"\\n\")\n",
        "s.remove(\" \")\n",
        "# s.remove(\",\")\n",
        "# s.remove(\".\")\n",
        "unique = list(set(s))\n",
        "unique.sort()\n",
        "vocab = dict(zip(unique, range(1,len(unique)+1)))\n",
        "VOCAB_SIZE = len(vocab)\n",
        "vocab"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': 1,\n",
              " '.': 2,\n",
              " '0': 3,\n",
              " '1': 4,\n",
              " '2': 5,\n",
              " '3': 6,\n",
              " '4': 7,\n",
              " '5': 8,\n",
              " '6': 9,\n",
              " '8': 10,\n",
              " '9': 11,\n",
              " ':': 12,\n",
              " 'C': 13,\n",
              " 'F': 14,\n",
              " 'L': 15,\n",
              " 'N': 16,\n",
              " 'S': 17,\n",
              " 'a': 18,\n",
              " 'b': 19,\n",
              " 'c': 20,\n",
              " 'd': 21,\n",
              " 'e': 22,\n",
              " 'f': 23,\n",
              " 'g': 24,\n",
              " 'h': 25,\n",
              " 'i': 26,\n",
              " 'j': 27,\n",
              " 'm': 28,\n",
              " 'n': 29,\n",
              " 'o': 30,\n",
              " 'p': 31,\n",
              " 'r': 32,\n",
              " 's': 33,\n",
              " 't': 34,\n",
              " 'u': 35,\n",
              " 'w': 36,\n",
              " 'y': 37}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "B_bKxVOBveDp",
        "outputId": "b463b2f0-ed05-4c82-94f1-6ac5707dbc0e"
      },
      "source": [
        "def encode(name, maxsize):\n",
        "  encoding = []\n",
        "  if name is None: return name\n",
        "  for c in name:\n",
        "    if c in vocab:\n",
        "      encoding.append(vocab[c])\n",
        "  if len(encoding) < maxsize:\n",
        "    for i in range(maxsize-len(encoding)):\n",
        "      encoding.append(0)\n",
        "  \n",
        "  return encoding\n",
        " \n",
        " \n",
        "def preprocess(data, col = 'word', maxsize = 43):\n",
        "  new_index = data[col].str.len().sort_values().index\n",
        "  data = data.reindex(new_index)\n",
        "  # maxsize = len(data[col].dropna().iloc[-1])\n",
        "\n",
        "  data[col] = data[col].apply(lambda  x: encode(str(x), maxsize = maxsize))\n",
        "  return data.dropna()\n",
        " \n",
        "# train_data['word'] = train_data['word'].dropna()\n",
        "\n",
        "\n",
        "# print(MAX_WORD_SIZE)\n",
        "train_data_pre = preprocess(train_data)\n",
        "MAX_WORD_SIZE = len(train_data_pre.iloc[-1,0])\n",
        "MAX_WORD_SIZE = 43\n",
        "\n",
        "train_data_pre"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>220661</th>\n",
              "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199532</th>\n",
              "      <td>[18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75209</th>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75212</th>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199524</th>\n",
              "      <td>[18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124574</th>\n",
              "      <td>[18, 26, 29, 34, 26, 34, 24, 32, 22, 18, 34, 3...</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146350</th>\n",
              "      <td>[20, 30, 28, 31, 35, 34, 22, 32, 26, 29, 34, 2...</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146209</th>\n",
              "      <td>[20, 30, 28, 31, 35, 34, 22, 32, 26, 29, 34, 2...</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146095</th>\n",
              "      <td>[20, 30, 28, 31, 35, 34, 22, 32, 26, 29, 34, 2...</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118420</th>\n",
              "      <td>[22, 31, 35, 19, 26, 20, 18, 29, 24, 30, 22, 3...</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>211727 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     word  pos\n",
              "220661  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    .\n",
              "199532  [18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   DT\n",
              "75209   [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    ,\n",
              "75212   [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    ,\n",
              "199524  [18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   DT\n",
              "...                                                   ...  ...\n",
              "124574  [18, 26, 29, 34, 26, 34, 24, 32, 22, 18, 34, 3...   JJ\n",
              "146350  [20, 30, 28, 31, 35, 34, 22, 32, 26, 29, 34, 2...   JJ\n",
              "146209  [20, 30, 28, 31, 35, 34, 22, 32, 26, 29, 34, 2...   JJ\n",
              "146095  [20, 30, 28, 31, 35, 34, 22, 32, 26, 29, 34, 2...   JJ\n",
              "118420  [22, 31, 35, 19, 26, 20, 18, 29, 24, 30, 22, 3...  NNP\n",
              "\n",
              "[211727 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "6kFNNAeEzdxO",
        "outputId": "fe352154-3e84-4171-b6c0-10ae81bcfb45"
      },
      "source": [
        "test_data_pre = preprocess(test_data)\n",
        "# MAX_WORD_SIZE_TEST = len(test_data_pre['word'].dropna().iloc[-1])\n",
        "test_data_pre"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49387</th>\n",
              "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9741</th>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44013</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>CC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9747</th>\n",
              "      <td>[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44015</th>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37899</th>\n",
              "      <td>[22, 33, 33, 22, 32, 21, 22, 22, 30, 31, 22, 2...</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32650</th>\n",
              "      <td>[26, 29, 34, 22, 32, 29, 18, 34, 26, 30, 29, 1...</td>\n",
              "      <td>NNS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31879</th>\n",
              "      <td>[36, 22, 32, 22, 18, 26, 29, 34, 25, 26, 33, 3...</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9180</th>\n",
              "      <td>[31, 32, 22, 33, 26, 21, 22, 29, 34, 29, 18, 3...</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3156</th>\n",
              "      <td>[20, 18, 31, 26, 34, 18, 26, 33, 34, 22, 31, 3...</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47377 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    word  pos\n",
              "49387  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    .\n",
              "9741   [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    ,\n",
              "44013  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   CC\n",
              "9747   [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    .\n",
              "44015  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    ,\n",
              "...                                                  ...  ...\n",
              "37899  [22, 33, 33, 22, 32, 21, 22, 22, 30, 31, 22, 2...   JJ\n",
              "32650  [26, 29, 34, 22, 32, 29, 18, 34, 26, 30, 29, 1...  NNS\n",
              "31879  [36, 22, 32, 22, 18, 26, 29, 34, 25, 26, 33, 3...   JJ\n",
              "9180   [31, 32, 22, 33, 26, 21, 22, 29, 34, 29, 18, 3...   NN\n",
              "3156   [20, 18, 31, 26, 34, 18, 26, 33, 34, 22, 31, 3...   JJ\n",
              "\n",
              "[47377 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbHRL8wq42co",
        "outputId": "4e3d45a1-207a-4dad-864f-b675a5d0909a"
      },
      "source": [
        "train_x = np.array([np.array(item) for item in train_data_pre['word']])\n",
        "test_x = np.array([np.array(item) for item in test_data_pre['word']])\n",
        "train_x.shape, test_x.shape\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((211727, 43), (47377, 43))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOtU7XzP5Ab8",
        "outputId": "4137edb7-f851-40c1-97d3-818d2abaeb77"
      },
      "source": [
        "POS_TAGS_DICT = {}\n",
        "for index, item in enumerate(set(train_data['pos'].dropna()),0):\n",
        "  POS_TAGS_DICT[item] = index\n",
        "def encode_labels(labels):\n",
        "  return np.array([POS_TAGS_DICT[item] for item in labels])\n",
        "\n",
        "def embed_one_hot(data_series, VOCAB_SIZE): #, labels = None\n",
        "  X = []\n",
        "  Y = []\n",
        "  l = []\n",
        "  def fill_position(position, size):\n",
        "    t = np.zeros(size)\n",
        "    if position < len(t):\n",
        "      t[position] = 1\n",
        "    return t\n",
        " \n",
        "  for item in data_series:\n",
        "    l = fill_position(item, VOCAB_SIZE)\n",
        "    l = np.array(l)\n",
        "    X.append(l)\n",
        "  X = np.array(X)\n",
        "  return X\n",
        "\n",
        "\n",
        "POS_TAGS = len(train_data['pos'].dropna().unique())\n",
        "\n",
        "\n",
        "train_y = encode_labels(train_data_pre['pos'])\n",
        "train_y_embed = embed_one_hot(train_y, POS_TAGS)\n",
        "test_y = encode_labels(test_data_pre['pos'])\n",
        "test_y_embed = embed_one_hot(test_y, POS_TAGS)\n",
        "\n",
        "\n",
        "\n",
        "train_y_embed"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGzcE4IaHD9F",
        "outputId": "92415be6-cf37-4c73-aea8-39d38895b490"
      },
      "source": [
        "MAX_WORD_SIZE, POS_TAGS, POS_TAGS_DICT"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43,\n",
              " 44,\n",
              " {'#': 38,\n",
              "  '$': 5,\n",
              "  \"''\": 25,\n",
              "  '(': 1,\n",
              "  ')': 3,\n",
              "  ',': 16,\n",
              "  '.': 13,\n",
              "  ':': 23,\n",
              "  'CC': 40,\n",
              "  'CD': 22,\n",
              "  'DT': 14,\n",
              "  'EX': 31,\n",
              "  'FW': 34,\n",
              "  'IN': 29,\n",
              "  'JJ': 24,\n",
              "  'JJR': 0,\n",
              "  'JJS': 35,\n",
              "  'MD': 2,\n",
              "  'NN': 27,\n",
              "  'NNP': 10,\n",
              "  'NNPS': 28,\n",
              "  'NNS': 39,\n",
              "  'PDT': 32,\n",
              "  'POS': 36,\n",
              "  'PRP': 6,\n",
              "  'PRP$': 8,\n",
              "  'RB': 17,\n",
              "  'RBR': 19,\n",
              "  'RBS': 30,\n",
              "  'RP': 21,\n",
              "  'SYM': 9,\n",
              "  'TO': 33,\n",
              "  'UH': 12,\n",
              "  'VB': 4,\n",
              "  'VBD': 20,\n",
              "  'VBG': 11,\n",
              "  'VBN': 43,\n",
              "  'VBP': 7,\n",
              "  'VBZ': 18,\n",
              "  'WDT': 15,\n",
              "  'WP': 26,\n",
              "  'WP$': 37,\n",
              "  'WRB': 41,\n",
              "  '``': 42})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8M-MLaWuUOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10e1a44-ba37-4d67-9c52-de3c6e1c2a1c"
      },
      "source": [
        "\n",
        "\n",
        "# TRAINING CONFIGS\n",
        "callback = EarlyStopping(monitor='val_accuracy', patience=5,restore_best_weights=True)\n",
        "EPOCHS = 5\n",
        "HIDDEN_UNITS = 100\n",
        "# DROPOUT = 0.2\n",
        "EMBEDDING_SIZE = 25\n",
        "# OUTPUT_SIZE = 1\n",
        "# OPTIM = Adam(learning_rate=0.001)\n",
        "# VALIDATION_SPLIT = 0.2\n",
        "# METRICS = ['accuracy']\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(input_dim=VOCAB_SIZE+1, output_dim=EMBEDDING_SIZE, input_length=MAX_WORD_SIZE))\n",
        "model.add(layers.Convolution1D(filters=HIDDEN_UNITS, kernel_size= 3, activation=\"relu\"))\n",
        "model.add(MaxPool1D(2))\n",
        "# model.add(layers.SimpleRNN(5))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(POS_TAGS, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics = ['accuracy'])\n",
        "print(model.summary())\n",
        "print(model.output_shape)\n",
        "history = model.fit(train_x, train_y_embed, epochs=EPOCHS)#, validation_split = VALIDATION_SPLIT,callbacks=[callback])\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 43, 25)            950       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 41, 100)           7600      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 20, 100)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 44)                88044     \n",
            "=================================================================\n",
            "Total params: 96,594\n",
            "Trainable params: 96,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "(None, 44)\n",
            "Epoch 1/5\n",
            "6617/6617 [==============================] - 43s 6ms/step - loss: 1.2558 - accuracy: 0.6268\n",
            "Epoch 2/5\n",
            "6617/6617 [==============================] - 42s 6ms/step - loss: 0.5924 - accuracy: 0.8082\n",
            "Epoch 3/5\n",
            "6617/6617 [==============================] - 42s 6ms/step - loss: 0.5227 - accuracy: 0.8305\n",
            "Epoch 4/5\n",
            "6617/6617 [==============================] - 42s 6ms/step - loss: 0.4800 - accuracy: 0.8429\n",
            "Epoch 5/5\n",
            "6617/6617 [==============================] - 41s 6ms/step - loss: 0.4572 - accuracy: 0.8513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaTpKwX-J-JJ"
      },
      "source": [
        "test_y_pred = model.predict(test_x)\n",
        "train_y_pred = model.predict(train_x)\n",
        "# test_y_pred[:,0]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYg7z0CAMo0U"
      },
      "source": [
        "train_y_pred_max = train_y_pred.argmax(axis = 1)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc6QyEflI_Bu"
      },
      "source": [
        "# from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
        "# import seaborn as sn\n",
        "\n",
        "# # cm = confusion_matrix(train_y, train_y_pred,normalize='true')\n",
        "\n",
        "# # df_cm = pd.DataFrame(cm, index = [i for i in POS_TAGS_DICT],\n",
        "# #                   columns = [i for i in POS_TAGS_DICT])\n",
        "# # plt.figure(figsize = (10,7))\n",
        "# # sn.heatmap(df_cm, annot=True)\n",
        "# plot_confusion_matrix(model, train_x, train_y, normalize='true')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP6V4DWUEgvo",
        "outputId": "e46b7a78-2cfd-4901-ca25-fad153283681"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_34 (Embedding)     (None, 43, 25)            1000      \n",
            "_________________________________________________________________\n",
            "conv1d_34 (Conv1D)           (None, 42, 100)           5100      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_32 (MaxPooling (None, 21, 100)           0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 2100)              0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 45)                94545     \n",
            "=================================================================\n",
            "Total params: 100,645\n",
            "Trainable params: 100,645\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CJUVLezQsIB",
        "outputId": "08ea1965-8061-469c-95e7-e107d8966742"
      },
      "source": [
        "sentences_end_points = np.where(train_data['word'].str.contains('\\n'))[0]\n",
        "sentences_end_points"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    37,     65,     95, ..., 220615, 220635, 220662])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FvYTrjlQsBj",
        "outputId": "25d3f114-366c-4262-bf29-cb19982d8f39"
      },
      "source": [
        "ll = []\n",
        "for index, item in enumerate(sentences_end_points, 0):\n",
        "  if index == 0:\n",
        "    ll.append(list(train_data['pos'][0:item]))\n",
        "  else:\n",
        "    ll.append(list(train_data['pos'][sentences_end_points[index-1]+1:item]))\n",
        "\n",
        "ll[1]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NNP',\n",
              " 'IN',\n",
              " 'DT',\n",
              " 'NNP',\n",
              " 'NNP',\n",
              " 'NNP',\n",
              " 'POS',\n",
              " 'VBN',\n",
              " 'NN',\n",
              " 'TO',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'JJ',\n",
              " 'NN',\n",
              " 'VBZ',\n",
              " 'VBN',\n",
              " 'TO',\n",
              " 'VB',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'DT',\n",
              " 'JJ',\n",
              " 'NN',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRrT7WNTcPa4",
        "outputId": "9569682b-53ea-4eda-97df-1181bddd6237"
      },
      "source": [
        "POS_TAGS_DICT"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'#': 38,\n",
              " '$': 5,\n",
              " \"''\": 25,\n",
              " '(': 1,\n",
              " ')': 3,\n",
              " ',': 16,\n",
              " '.': 13,\n",
              " ':': 23,\n",
              " 'CC': 40,\n",
              " 'CD': 22,\n",
              " 'DT': 14,\n",
              " 'EX': 31,\n",
              " 'FW': 34,\n",
              " 'IN': 29,\n",
              " 'JJ': 24,\n",
              " 'JJR': 0,\n",
              " 'JJS': 35,\n",
              " 'MD': 2,\n",
              " 'NN': 27,\n",
              " 'NNP': 10,\n",
              " 'NNPS': 28,\n",
              " 'NNS': 39,\n",
              " 'PDT': 32,\n",
              " 'POS': 36,\n",
              " 'PRP': 6,\n",
              " 'PRP$': 8,\n",
              " 'RB': 17,\n",
              " 'RBR': 19,\n",
              " 'RBS': 30,\n",
              " 'RP': 21,\n",
              " 'SYM': 9,\n",
              " 'TO': 33,\n",
              " 'UH': 12,\n",
              " 'VB': 4,\n",
              " 'VBD': 20,\n",
              " 'VBG': 11,\n",
              " 'VBN': 43,\n",
              " 'VBP': 7,\n",
              " 'VBZ': 18,\n",
              " 'WDT': 15,\n",
              " 'WP': 26,\n",
              " 'WP$': 37,\n",
              " 'WRB': 41,\n",
              " '``': 42}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kajOlMKeQm5c",
        "outputId": "3d6a1fce-67cb-4608-b0bd-01a18d2d739e"
      },
      "source": [
        "def transition_matrix(transitions):\n",
        "    n = 44 #number of states\n",
        "\n",
        "    M = [[0]*n for _ in range(n)]\n",
        "\n",
        "    for (i,j) in zip(transitions,transitions[1:]):\n",
        "        M[i][j] += 1\n",
        "\n",
        "    #now convert to probabilities:\n",
        "    for row in M:\n",
        "        s = sum(row)\n",
        "        if s > 0:\n",
        "            row[:] = [f/s for f in row]\n",
        "    return M\n",
        "\n",
        "#test:\n",
        "\n",
        "# t = [1,1,2,6,8,5,5,7,8,8,1,1,4,5,5,0,0,0,1,1,4,4,5,1,3,3,4,5,4,1,1]\n",
        "sums = np.zeros((POS_TAGS, POS_TAGS))\n",
        "for item in ll:\n",
        "  t = [POS_TAGS_DICT[i] for i in item]\n",
        "\n",
        "  m = transition_matrix(t)\n",
        "  # print(len(m))\n",
        "  sums += np.array(m)\n",
        "# for row in m: print(' '.join('{0:.2f}'.format(x) for x in row))\n",
        "sums.shape"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44, 44)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlQQO70mde4z",
        "outputId": "e293a03f-8f03-4f63-939f-5ac25b780c9a"
      },
      "source": [
        "transition_table = np.array([sums[i]/np.sum(sums[i]) for i in range(len(sums))])\n",
        "transition_table.shape"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44, 44)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZZxTqjwecLr",
        "outputId": "02f048ef-35bb-4d18-d42e-eb89be517502"
      },
      "source": [
        "emission_table = train_y_pred\n",
        "emission_table.shape"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(211727, 44)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyAFerUZfK9t",
        "outputId": "f03e816e-e101-45d1-e9d8-4b287270f99b"
      },
      "source": [
        "train_data['pos'] = train_data['pos'].dropna()\n",
        "pi = []\n",
        "for k, v in Counter(train_data['pos'].dropna()).items():\n",
        "  pi.append(v/len(train_data['pos'].dropna()))\n",
        "\n",
        "initial_table = np.array(pi)\n",
        "initial_table"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.42386186e-01, 1.07515810e-01, 8.65973636e-02, 2.19527977e-02,\n",
              "       3.12052785e-02, 2.24959500e-02, 2.39978841e-02, 2.84186712e-02,\n",
              "       6.18012818e-02, 6.43233976e-02, 9.39133885e-02, 5.08673906e-02,\n",
              "       2.53722955e-02, 8.35509878e-03, 4.16904788e-02, 1.35457452e-02,\n",
              "       1.54538628e-02, 8.88408186e-03, 3.92722704e-02, 7.23100974e-03,\n",
              "       7.05153334e-03, 3.18570612e-02, 9.72951017e-04, 1.02348779e-02,\n",
              "       1.70030275e-04, 1.29411931e-03, 8.26536058e-03, 1.32718076e-03,\n",
              "       1.98368654e-03, 1.80421014e-02, 1.76642563e-03, 2.49850043e-03,\n",
              "       1.51610328e-03, 4.02877290e-03, 4.51052535e-03, 2.25762420e-03,\n",
              "       9.02105069e-04, 2.59768475e-04, 3.92014245e-04, 4.94504716e-03,\n",
              "       1.79476401e-04, 1.65307212e-04, 2.83383791e-05, 7.08459478e-05])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWq2YkxugHqN"
      },
      "source": [
        "from typing import List, Optional, Tuple\n",
        "\n",
        "def step(mu_prev: np.ndarray,\n",
        "         emission_probs: np.ndarray,\n",
        "         transition_probs: np.ndarray,\n",
        "         observed_state: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Runs one step of the Viterbi algorithm.\n",
        "    \n",
        "    Args:\n",
        "        mu_prev: probability distribution with shape (num_hidden),\n",
        "            the previous mu\n",
        "        emission_probs: the emission probability matrix (num_hidden,\n",
        "            num_observed)\n",
        "        transition_probs: the transition probability matrix, with\n",
        "            shape (num_hidden, num_hidden)\n",
        "        observed_state: the observed state at the current step\n",
        "    \n",
        "    Returns:\n",
        "        - the mu for the next step\n",
        "        - the maximizing previous state, before the current state,\n",
        "          as an int array with shape (num_hidden)\n",
        "    \"\"\"\n",
        "    \n",
        "    pre_max = mu_prev * transition_probs.T\n",
        "    max_prev_states = np.argmax(pre_max, axis=1)\n",
        "    max_vals = pre_max[np.arange(len(max_prev_states)), max_prev_states]\n",
        "    mu_new = max_vals * emission_probs[:, observed_state]\n",
        "    \n",
        "    return mu_new, max_prev_states\n",
        "\n",
        "\n",
        "def viterbi(emission_probs: np.ndarray,\n",
        "            transition_probs: np.ndarray,\n",
        "            start_probs: np.ndarray,\n",
        "            observed_states: List[int]) -> Tuple[List[int], float]:\n",
        "    \"\"\"Runs the Viterbi algorithm to get the most likely state sequence.\n",
        "    \n",
        "    Args:\n",
        "        emission_probs: the emission probability matrix (num_hidden,\n",
        "            num_observed)\n",
        "        transition_probs: the transition probability matrix, with\n",
        "            shape (num_hidden, num_hidden)\n",
        "        start_probs: the initial probabilies for each state, with shape\n",
        "            (num_hidden)\n",
        "        observed_states: the observed states at each step\n",
        "    \n",
        "    Returns:\n",
        "        - the most likely series of states\n",
        "        - the joint probability of that series of states and the observed\n",
        "    \"\"\"\n",
        "    \n",
        "    # Runs the forward pass, storing the most likely previous state.\n",
        "    mu = start_probs * emission_probs[:, observed_states[0]]\n",
        "    all_prev_states = []\n",
        "    for observed_state in observed_states[1:]:\n",
        "        mu, prevs = step(mu, emission_probs, transition_probs, observed_state)\n",
        "        all_prev_states.append(prevs)\n",
        "    \n",
        "    # Traces backwards to get the maximum likelihood sequence.\n",
        "    state = np.argmax(mu)\n",
        "    sequence_prob = mu[state]\n",
        "    state_sequence = [state]\n",
        "    for prev_states in all_prev_states[::-1]:\n",
        "        state = prev_states[state]\n",
        "        state_sequence.append(state)\n",
        "    \n",
        "    return state_sequence[::-1], sequence_prob"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi-TwSqIgX3t"
      },
      "source": [
        "max_seq, seq_prob = viterbi(\n",
        "    emission_table.T,\n",
        "    transition_table,\n",
        "    initial_table,\n",
        "    [4,1,24,2],\n",
        ")"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBc9E8S4hAII",
        "outputId": "644cd864-8a02-4eec-d244-8243720be277"
      },
      "source": [
        "max_seq"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14, 10, 10, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    }
  ]
}
